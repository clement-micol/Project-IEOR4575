{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2194e8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From https://github.com/clement-micol/Project-IEOR4575\r\n",
      " * branch              HEAD       -> FETCH_HEAD\r\n",
      "Already up to date.\r\n"
     ]
    }
   ],
   "source": [
    "!git pull https://clement-micol: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@github.com/clement-micol/Project-IEOR4575.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8fc4cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f0a9a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master be13e7cf] Updated the checkpoint data\r\n",
      " 1 file changed, 102 insertions(+), 48 deletions(-)\r\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Updated the checkpoint data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bbf9fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Invalid username or password.\r\n",
      "fatal: Authentication failed for 'https://clement-micol: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@github.com/clement-micol/Project-IEOR4575.git/'\r\n"
     ]
    }
   ],
   "source": [
    "!git push https://clement-micol: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@github.com/clement-micol/Project-IEOR4575.git master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b89e9bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow_addons as tfa\n",
    "from lib import Nam_models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9175e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_race_mini = pd.read_csv(\"./data/race_minisector.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c70a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_race_mini[\"Minisector\"] = laps_race_mini[\"Minisector\"].apply(lambda x:np.cos(2*np.pi*x/49))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16ad1164",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_race_mini[\"Acceleration\"] = laps_race_mini[\"Speed-1\"].diff().fillna(method=\"backfill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a15a0704",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_qualification_mini = pd.read_csv(\"./data/qualification_minisector.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9430018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_race = pd.read_csv(\"./data/laps_race.csv\")\n",
    "laps_qualification = pd.read_csv(\"./data/laps_qualification.csv\")\n",
    "laps = pd.concat([laps_race,laps_qualification])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d9bc4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_race[\"LapTime-1\"]=laps_race[\"LapTime\"].shift().fillna(method=\"backfill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4a1ad2",
   "metadata": {},
   "source": [
    "## Predicting the lap time :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06f26de",
   "metadata": {},
   "source": [
    "## Processing the data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50bd388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def spliting_data(average_speed):\n",
    "  X_train_list = []\n",
    "  X_test_list = []\n",
    "  y_train_list = []\n",
    "  y_test_list = []\n",
    "  for i in range(10):\n",
    "    X = average_speed[average_speed['Driver']==i]\n",
    "    y = X['Speed']\n",
    "    X = X[['Minisector','Compound','TyreLife','Distance','Piting','TrackStatus',\"Driver\",'Speed-1']]\n",
    "    X[\"Acceleration\"] = X[\"Speed-1\"].diff().fillna(method=\"backfill\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
    "    X_train_list.append(X_train)\n",
    "    X_test_list.append(X_test)\n",
    "    y_train_list.append(y_train)\n",
    "    y_test_list.append(y_test)\n",
    "  return X_train_list, X_test_list, y_train_list, y_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f11a3c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_race = laps_race[~laps_race[\"TrackStatus\"].isin([1,2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b9892ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "laps_race = laps_race[[\"LapNumber\",\"TyreLife\",\"Compound\",\"Piting\",\"DriverNumber\",\"LapTime\",\"DistanceToDriverAhead\",\"LapTime-1\"]].dropna()\n",
    "X = laps_race[[\"LapNumber\",\"TyreLife\",\"Compound\",\"Piting\",\"DriverNumber\",\"DistanceToDriverAhead\",\"LapTime-1\"]]\n",
    "y = laps_race[\"LapTime\"]\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "mean = np.mean(y)\n",
    "std = np.std(y)\n",
    "X = scaler_X.fit_transform(X.to_numpy())\n",
    "y = scaler_y.fit_transform(np.reshape(y.to_numpy(),(-1,1)))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f74afd",
   "metadata": {},
   "source": [
    "## Implement the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bc77e3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "def NAM(num_input=7,dropout_ratio = 0.15,regularizer_value = 0.005, mlp_size=64, output_lstm_size = 12, decay_rate=0.95,lstm_input=32, initial_learning_rate=7.5e-3):\n",
    "    feature_input = layers.Input(shape=(1,num_input))\n",
    "    embbed_feature_input = layers.Lambda(lambda x : tf.split(x,num_input,axis=2))(feature_input)\n",
    "    feature_output = []\n",
    "    for i in range(num_input-1):\n",
    "        x = layers.Dense(mlp_size,activation=\"relu\",kernel_initializer=\"he_uniform\")(embbed_feature_input[i])# or 64 as best hyperparameters\n",
    "        x = layers.Dense(mlp_size,activation=\"relu\",kernel_initializer=\"he_uniform\")(x)\n",
    "        x = layers.Dense(mlp_size//2,activation=\"relu\",kernel_initializer=\"he_uniform\")(x)\n",
    "        x = layers.Dropout(dropout_ratio)(x)\n",
    "        feature_output.append(x)\n",
    "    for i in range(num_input-1,num_input):\n",
    "        x = layers.LSTM(lstm_input, return_sequences=True)(embbed_feature_input[i])\n",
    "        x = layers.LSTM(mlp_size//2)(x)\n",
    "        feature_output.append(x)\n",
    "    combined_output = layers.Add()(feature_output)\n",
    "    combined_output = layers.Dropout(dropout_ratio)(combined_output)\n",
    "    combined_output = layers.BatchNormalization(trainable=True)(combined_output)\n",
    "    lstm_output = layers.LSTM(output_lstm_size)(combined_output)\n",
    "    output = layers.Dense(1,activation=\"linear\",kernel_initializer=\"he_uniform\", kernel_regularizer=l2(regularizer_value))(lstm_output)\n",
    "    model = keras.Model(inputs=feature_input,outputs=output)\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate,\n",
    "        decay_steps=100000,\n",
    "        decay_rate=decay_rate,\n",
    "        staircase=True\n",
    "    )\n",
    "    optimizer = tfa.optimizers.AdamW(learning_rate=lr_schedule,weight_decay=5e-6) #lr : [7.5e-4,5e-4], weight_decay : [5e-6,1e-6]\n",
    "    model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=keras.losses.MeanSquaredError(),\n",
    "            metrics=[\n",
    "                keras.metrics.RootMeanSquaredError(name=\"RMSE\"),\n",
    "                keras.metrics.MeanAbsoluteError(name=\"MAE\"),\n",
    "            ],\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a4368439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "2022-04-21 22:26:37.248445: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-04-21 22:26:37.248503: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (deeplearning-1-vm): /proc/driver/nvidia/version does not exist\n",
      "2022-04-21 22:26:37.249413: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-21 22:26:37.270779: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-04-21 22:26:37.270827: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (deeplearning-1-vm): /proc/driver/nvidia/version does not exist\n",
      "2022-04-21 22:26:37.271487: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-21 22:26:37.332667: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-04-21 22:26:37.332726: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (deeplearning-1-vm): /proc/driver/nvidia/version does not exist\n",
      "2022-04-21 22:26:37.333357: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-21 22:26:37.400134: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-04-21 22:26:37.400208: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (deeplearning-1-vm): /proc/driver/nvidia/version does not exist\n",
      "2022-04-21 22:26:37.400913: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1e6fca2cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7df6f60cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fba2b763cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa1db822cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1e8cec5710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7e14f64710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fba4857a710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa1dbd8f710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.394359 using {'dropout_ratio': 0.25, 'initial_learning_rate': 0.005, 'regularizer_value': 0.005}\n",
      "-0.556621 (0.299952) with: {'dropout_ratio': 0.1, 'initial_learning_rate': 0.005, 'regularizer_value': 0.005}\n",
      "-0.679382 (0.546081) with: {'dropout_ratio': 0.1, 'initial_learning_rate': 0.005, 'regularizer_value': 0.01}\n",
      "-0.773386 (0.773053) with: {'dropout_ratio': 0.1, 'initial_learning_rate': 0.005, 'regularizer_value': 0.05}\n",
      "-0.661513 (0.413607) with: {'dropout_ratio': 0.1, 'initial_learning_rate': 0.005, 'regularizer_value': 0.1}\n",
      "-0.561858 (0.376852) with: {'dropout_ratio': 0.1, 'initial_learning_rate': 0.0075, 'regularizer_value': 0.005}\n",
      "-0.563965 (0.383984) with: {'dropout_ratio': 0.1, 'initial_learning_rate': 0.0075, 'regularizer_value': 0.01}\n",
      "-0.849993 (0.747712) with: {'dropout_ratio': 0.1, 'initial_learning_rate': 0.0075, 'regularizer_value': 0.05}\n",
      "-0.529082 (0.270220) with: {'dropout_ratio': 0.1, 'initial_learning_rate': 0.0075, 'regularizer_value': 0.1}\n",
      "-0.503488 (0.278886) with: {'dropout_ratio': 0.1, 'initial_learning_rate': 0.01, 'regularizer_value': 0.005}\n",
      "-0.599203 (0.357201) with: {'dropout_ratio': 0.1, 'initial_learning_rate': 0.01, 'regularizer_value': 0.01}\n",
      "-0.596893 (0.479495) with: {'dropout_ratio': 0.1, 'initial_learning_rate': 0.01, 'regularizer_value': 0.05}\n",
      "-0.853347 (0.590958) with: {'dropout_ratio': 0.1, 'initial_learning_rate': 0.01, 'regularizer_value': 0.1}\n",
      "-0.457188 (0.248260) with: {'dropout_ratio': 0.15, 'initial_learning_rate': 0.005, 'regularizer_value': 0.005}\n",
      "-0.508859 (0.231459) with: {'dropout_ratio': 0.15, 'initial_learning_rate': 0.005, 'regularizer_value': 0.01}\n",
      "-0.650995 (0.479667) with: {'dropout_ratio': 0.15, 'initial_learning_rate': 0.005, 'regularizer_value': 0.05}\n",
      "-0.582964 (0.276521) with: {'dropout_ratio': 0.15, 'initial_learning_rate': 0.005, 'regularizer_value': 0.1}\n",
      "-0.491423 (0.250042) with: {'dropout_ratio': 0.15, 'initial_learning_rate': 0.0075, 'regularizer_value': 0.005}\n",
      "-0.580427 (0.403323) with: {'dropout_ratio': 0.15, 'initial_learning_rate': 0.0075, 'regularizer_value': 0.01}\n",
      "-0.537354 (0.375509) with: {'dropout_ratio': 0.15, 'initial_learning_rate': 0.0075, 'regularizer_value': 0.05}\n",
      "-0.623879 (0.303644) with: {'dropout_ratio': 0.15, 'initial_learning_rate': 0.0075, 'regularizer_value': 0.1}\n",
      "-0.620141 (0.474273) with: {'dropout_ratio': 0.15, 'initial_learning_rate': 0.01, 'regularizer_value': 0.005}\n",
      "-0.593901 (0.412382) with: {'dropout_ratio': 0.15, 'initial_learning_rate': 0.01, 'regularizer_value': 0.01}\n",
      "-0.712060 (0.479565) with: {'dropout_ratio': 0.15, 'initial_learning_rate': 0.01, 'regularizer_value': 0.05}\n",
      "-0.613597 (0.312447) with: {'dropout_ratio': 0.15, 'initial_learning_rate': 0.01, 'regularizer_value': 0.1}\n",
      "-0.475290 (0.273899) with: {'dropout_ratio': 0.2, 'initial_learning_rate': 0.005, 'regularizer_value': 0.005}\n",
      "-0.629133 (0.376119) with: {'dropout_ratio': 0.2, 'initial_learning_rate': 0.005, 'regularizer_value': 0.01}\n",
      "-0.746010 (0.609734) with: {'dropout_ratio': 0.2, 'initial_learning_rate': 0.005, 'regularizer_value': 0.05}\n",
      "-0.658244 (0.485212) with: {'dropout_ratio': 0.2, 'initial_learning_rate': 0.005, 'regularizer_value': 0.1}\n",
      "-0.457519 (0.230749) with: {'dropout_ratio': 0.2, 'initial_learning_rate': 0.0075, 'regularizer_value': 0.005}\n",
      "-0.422198 (0.172881) with: {'dropout_ratio': 0.2, 'initial_learning_rate': 0.0075, 'regularizer_value': 0.01}\n",
      "-0.530856 (0.293916) with: {'dropout_ratio': 0.2, 'initial_learning_rate': 0.0075, 'regularizer_value': 0.05}\n",
      "-0.630705 (0.340442) with: {'dropout_ratio': 0.2, 'initial_learning_rate': 0.0075, 'regularizer_value': 0.1}\n",
      "-0.484135 (0.307252) with: {'dropout_ratio': 0.2, 'initial_learning_rate': 0.01, 'regularizer_value': 0.005}\n",
      "-0.408038 (0.220145) with: {'dropout_ratio': 0.2, 'initial_learning_rate': 0.01, 'regularizer_value': 0.01}\n",
      "-0.592827 (0.373484) with: {'dropout_ratio': 0.2, 'initial_learning_rate': 0.01, 'regularizer_value': 0.05}\n",
      "-0.778701 (0.466073) with: {'dropout_ratio': 0.2, 'initial_learning_rate': 0.01, 'regularizer_value': 0.1}\n",
      "-0.394359 (0.120392) with: {'dropout_ratio': 0.25, 'initial_learning_rate': 0.005, 'regularizer_value': 0.005}\n",
      "-0.521098 (0.251299) with: {'dropout_ratio': 0.25, 'initial_learning_rate': 0.005, 'regularizer_value': 0.01}\n",
      "-0.455015 (0.262281) with: {'dropout_ratio': 0.25, 'initial_learning_rate': 0.005, 'regularizer_value': 0.05}\n",
      "-0.571082 (0.273768) with: {'dropout_ratio': 0.25, 'initial_learning_rate': 0.005, 'regularizer_value': 0.1}\n",
      "-0.470686 (0.145045) with: {'dropout_ratio': 0.25, 'initial_learning_rate': 0.0075, 'regularizer_value': 0.005}\n",
      "-0.511741 (0.399576) with: {'dropout_ratio': 0.25, 'initial_learning_rate': 0.0075, 'regularizer_value': 0.01}\n",
      "-0.548242 (0.244027) with: {'dropout_ratio': 0.25, 'initial_learning_rate': 0.0075, 'regularizer_value': 0.05}\n",
      "-0.647811 (0.323616) with: {'dropout_ratio': 0.25, 'initial_learning_rate': 0.0075, 'regularizer_value': 0.1}\n",
      "-0.477670 (0.229591) with: {'dropout_ratio': 0.25, 'initial_learning_rate': 0.01, 'regularizer_value': 0.005}\n",
      "-0.528367 (0.280673) with: {'dropout_ratio': 0.25, 'initial_learning_rate': 0.01, 'regularizer_value': 0.01}\n",
      "-0.636292 (0.333902) with: {'dropout_ratio': 0.25, 'initial_learning_rate': 0.01, 'regularizer_value': 0.05}\n",
      "-0.662452 (0.382348) with: {'dropout_ratio': 0.25, 'initial_learning_rate': 0.01, 'regularizer_value': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = KerasRegressor(build_fn = NAM, epochs=500, batch_size=512, verbose=0)\n",
    "param_grid = dict(regularizer_value=[0.005,0.01,0.05,0.1], dropout_ratio = [0.1,0.15,0.2,0.25],initial_learning_rate=[5e-3,7.5e-3,1e-2])\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\n",
    "grid_result = grid.fit(np.reshape(X,(X.shape[0],1,X.shape[1])), y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d58cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - 8s 821ms/step - loss: 0.9789 - RMSE: 0.9860 - MAE: 0.7813 - val_loss: 0.8038 - val_RMSE: 0.8928 - val_MAE: 0.7305\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6831 - RMSE: 0.8224 - MAE: 0.6331 - val_loss: 0.6965 - val_RMSE: 0.8303 - val_MAE: 0.6756\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6191 - RMSE: 0.7822 - MAE: 0.5964 - val_loss: 0.6558 - val_RMSE: 0.8052 - val_MAE: 0.6298\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5590 - RMSE: 0.7425 - MAE: 0.5620 - val_loss: 0.6888 - val_RMSE: 0.8251 - val_MAE: 0.6179\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5189 - RMSE: 0.7146 - MAE: 0.5325 - val_loss: 0.7924 - val_RMSE: 0.8854 - val_MAE: 0.6677\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5120 - RMSE: 0.7095 - MAE: 0.5225 - val_loss: 0.8024 - val_RMSE: 0.8908 - val_MAE: 0.6740\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5309 - RMSE: 0.7225 - MAE: 0.5373 - val_loss: 0.7362 - val_RMSE: 0.8528 - val_MAE: 0.6469\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5257 - RMSE: 0.7189 - MAE: 0.5312 - val_loss: 0.6651 - val_RMSE: 0.8101 - val_MAE: 0.6246\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5034 - RMSE: 0.7033 - MAE: 0.5265 - val_loss: 0.6252 - val_RMSE: 0.7851 - val_MAE: 0.6030\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5223 - RMSE: 0.7166 - MAE: 0.5318 - val_loss: 0.6214 - val_RMSE: 0.7828 - val_MAE: 0.5943\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4901 - RMSE: 0.6938 - MAE: 0.5211 - val_loss: 0.6259 - val_RMSE: 0.7857 - val_MAE: 0.5875\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4877 - RMSE: 0.6921 - MAE: 0.5175 - val_loss: 0.6402 - val_RMSE: 0.7946 - val_MAE: 0.5890\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4817 - RMSE: 0.6877 - MAE: 0.5030 - val_loss: 0.6398 - val_RMSE: 0.7943 - val_MAE: 0.5803\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4680 - RMSE: 0.6777 - MAE: 0.5004 - val_loss: 0.6075 - val_RMSE: 0.7737 - val_MAE: 0.5601\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4678 - RMSE: 0.6775 - MAE: 0.4936 - val_loss: 0.5780 - val_RMSE: 0.7545 - val_MAE: 0.5403\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4539 - RMSE: 0.6672 - MAE: 0.4920 - val_loss: 0.5576 - val_RMSE: 0.7408 - val_MAE: 0.5336\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4467 - RMSE: 0.6618 - MAE: 0.4914 - val_loss: 0.5440 - val_RMSE: 0.7315 - val_MAE: 0.5268\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4000 - RMSE: 0.6253 - MAE: 0.4623 - val_loss: 0.5376 - val_RMSE: 0.7270 - val_MAE: 0.5262\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4186 - RMSE: 0.6399 - MAE: 0.4623 - val_loss: 0.5236 - val_RMSE: 0.7172 - val_MAE: 0.5192\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4066 - RMSE: 0.6303 - MAE: 0.4595 - val_loss: 0.5239 - val_RMSE: 0.7173 - val_MAE: 0.5252\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3781 - RMSE: 0.6072 - MAE: 0.4544 - val_loss: 0.5145 - val_RMSE: 0.7106 - val_MAE: 0.5216\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3904 - RMSE: 0.6171 - MAE: 0.4580 - val_loss: 0.4825 - val_RMSE: 0.6877 - val_MAE: 0.5082\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3653 - RMSE: 0.5964 - MAE: 0.4476 - val_loss: 0.4594 - val_RMSE: 0.6707 - val_MAE: 0.4987\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3822 - RMSE: 0.6105 - MAE: 0.4487 - val_loss: 0.4366 - val_RMSE: 0.6535 - val_MAE: 0.4842\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3658 - RMSE: 0.5969 - MAE: 0.4373 - val_loss: 0.4178 - val_RMSE: 0.6390 - val_MAE: 0.4789\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3269 - RMSE: 0.5634 - MAE: 0.4075 - val_loss: 0.3933 - val_RMSE: 0.6196 - val_MAE: 0.4659\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3221 - RMSE: 0.5592 - MAE: 0.4095 - val_loss: 0.3783 - val_RMSE: 0.6073 - val_MAE: 0.4598\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3060 - RMSE: 0.5446 - MAE: 0.3975 - val_loss: 0.3753 - val_RMSE: 0.6048 - val_MAE: 0.4617\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3392 - RMSE: 0.5742 - MAE: 0.4016 - val_loss: 0.3736 - val_RMSE: 0.6034 - val_MAE: 0.4704\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3029 - RMSE: 0.5416 - MAE: 0.3869 - val_loss: 0.3576 - val_RMSE: 0.5899 - val_MAE: 0.4596\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2860 - RMSE: 0.5256 - MAE: 0.3795 - val_loss: 0.3603 - val_RMSE: 0.5919 - val_MAE: 0.4734\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2772 - RMSE: 0.5170 - MAE: 0.3688 - val_loss: 0.3596 - val_RMSE: 0.5912 - val_MAE: 0.4765\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2634 - RMSE: 0.5032 - MAE: 0.3589 - val_loss: 0.3573 - val_RMSE: 0.5890 - val_MAE: 0.4800\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2468 - RMSE: 0.4861 - MAE: 0.3430 - val_loss: 0.3654 - val_RMSE: 0.5957 - val_MAE: 0.4960\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2465 - RMSE: 0.4857 - MAE: 0.3414 - val_loss: 0.3737 - val_RMSE: 0.6025 - val_MAE: 0.5021\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2605 - RMSE: 0.4999 - MAE: 0.3434 - val_loss: 0.3721 - val_RMSE: 0.6012 - val_MAE: 0.5064\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2478 - RMSE: 0.4870 - MAE: 0.3386 - val_loss: 0.3662 - val_RMSE: 0.5963 - val_MAE: 0.5026\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2436 - RMSE: 0.4826 - MAE: 0.3288 - val_loss: 0.3589 - val_RMSE: 0.5901 - val_MAE: 0.4838\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2417 - RMSE: 0.4805 - MAE: 0.3362 - val_loss: 0.3744 - val_RMSE: 0.6029 - val_MAE: 0.4959\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2353 - RMSE: 0.4737 - MAE: 0.3389 - val_loss: 0.3677 - val_RMSE: 0.5973 - val_MAE: 0.4868\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2285 - RMSE: 0.4664 - MAE: 0.3248 - val_loss: 0.3737 - val_RMSE: 0.6023 - val_MAE: 0.4965\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2382 - RMSE: 0.4767 - MAE: 0.3272 - val_loss: 0.3594 - val_RMSE: 0.5903 - val_MAE: 0.4902\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2397 - RMSE: 0.4783 - MAE: 0.3377 - val_loss: 0.3439 - val_RMSE: 0.5770 - val_MAE: 0.4709\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2297 - RMSE: 0.4677 - MAE: 0.3290 - val_loss: 0.3371 - val_RMSE: 0.5712 - val_MAE: 0.4650\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2369 - RMSE: 0.4755 - MAE: 0.3285 - val_loss: 0.3511 - val_RMSE: 0.5835 - val_MAE: 0.4735\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2407 - RMSE: 0.4797 - MAE: 0.3252 - val_loss: 0.3741 - val_RMSE: 0.6032 - val_MAE: 0.4875\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2243 - RMSE: 0.4626 - MAE: 0.3016 - val_loss: 0.3924 - val_RMSE: 0.6183 - val_MAE: 0.5016\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2077 - RMSE: 0.4445 - MAE: 0.3047 - val_loss: 0.4124 - val_RMSE: 0.6344 - val_MAE: 0.5198\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2198 - RMSE: 0.4581 - MAE: 0.3121 - val_loss: 0.3991 - val_RMSE: 0.6238 - val_MAE: 0.5105\n",
      "Epoch 50/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2011 - RMSE: 0.4371 - MAE: 0.3001 - val_loss: 0.3683 - val_RMSE: 0.5985 - val_MAE: 0.4805\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1942 - RMSE: 0.4290 - MAE: 0.3027 - val_loss: 0.3542 - val_RMSE: 0.5865 - val_MAE: 0.4666\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1978 - RMSE: 0.4331 - MAE: 0.3066 - val_loss: 0.3520 - val_RMSE: 0.5846 - val_MAE: 0.4678\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2130 - RMSE: 0.4504 - MAE: 0.3071 - val_loss: 0.3676 - val_RMSE: 0.5980 - val_MAE: 0.4898\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1842 - RMSE: 0.4174 - MAE: 0.2847 - val_loss: 0.3872 - val_RMSE: 0.6143 - val_MAE: 0.5114\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1931 - RMSE: 0.4280 - MAE: 0.2888 - val_loss: 0.3763 - val_RMSE: 0.6054 - val_MAE: 0.5020\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1818 - RMSE: 0.4148 - MAE: 0.2929 - val_loss: 0.3633 - val_RMSE: 0.5946 - val_MAE: 0.4874\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1975 - RMSE: 0.4334 - MAE: 0.2913 - val_loss: 0.3543 - val_RMSE: 0.5870 - val_MAE: 0.4793\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1868 - RMSE: 0.4208 - MAE: 0.2924 - val_loss: 0.3506 - val_RMSE: 0.5838 - val_MAE: 0.4762\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1910 - RMSE: 0.4257 - MAE: 0.2823 - val_loss: 0.3366 - val_RMSE: 0.5717 - val_MAE: 0.4611\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1843 - RMSE: 0.4177 - MAE: 0.2903 - val_loss: 0.3458 - val_RMSE: 0.5796 - val_MAE: 0.4692\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2086 - RMSE: 0.4458 - MAE: 0.2929 - val_loss: 0.3557 - val_RMSE: 0.5881 - val_MAE: 0.4732\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1954 - RMSE: 0.4308 - MAE: 0.2918 - val_loss: 0.4025 - val_RMSE: 0.6267 - val_MAE: 0.5068\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2156 - RMSE: 0.4537 - MAE: 0.3002 - val_loss: 0.3790 - val_RMSE: 0.6077 - val_MAE: 0.4972\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1870 - RMSE: 0.4212 - MAE: 0.2887 - val_loss: 0.3643 - val_RMSE: 0.5957 - val_MAE: 0.4908\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2051 - RMSE: 0.4423 - MAE: 0.2996 - val_loss: 0.3753 - val_RMSE: 0.6049 - val_MAE: 0.4896\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2043 - RMSE: 0.4416 - MAE: 0.3077 - val_loss: 0.3568 - val_RMSE: 0.5895 - val_MAE: 0.4680\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2125 - RMSE: 0.4509 - MAE: 0.3226 - val_loss: 0.3221 - val_RMSE: 0.5594 - val_MAE: 0.4373\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1845 - RMSE: 0.4187 - MAE: 0.2930 - val_loss: 0.3085 - val_RMSE: 0.5471 - val_MAE: 0.4247\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1993 - RMSE: 0.4360 - MAE: 0.2974 - val_loss: 0.3096 - val_RMSE: 0.5482 - val_MAE: 0.4273\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1909 - RMSE: 0.4264 - MAE: 0.2895 - val_loss: 0.3200 - val_RMSE: 0.5577 - val_MAE: 0.4390\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1808 - RMSE: 0.4146 - MAE: 0.2805 - val_loss: 0.3255 - val_RMSE: 0.5627 - val_MAE: 0.4406\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1880 - RMSE: 0.4233 - MAE: 0.2884 - val_loss: 0.3267 - val_RMSE: 0.5638 - val_MAE: 0.4367\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1740 - RMSE: 0.4064 - MAE: 0.2807 - val_loss: 0.3213 - val_RMSE: 0.5590 - val_MAE: 0.4363\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1644 - RMSE: 0.3944 - MAE: 0.2657 - val_loss: 0.3144 - val_RMSE: 0.5528 - val_MAE: 0.4365\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1864 - RMSE: 0.4212 - MAE: 0.2929 - val_loss: 0.3054 - val_RMSE: 0.5444 - val_MAE: 0.4283\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1721 - RMSE: 0.4038 - MAE: 0.2750 - val_loss: 0.3002 - val_RMSE: 0.5395 - val_MAE: 0.4201\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1916 - RMSE: 0.4273 - MAE: 0.2928 - val_loss: 0.3038 - val_RMSE: 0.5429 - val_MAE: 0.4250\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1635 - RMSE: 0.3931 - MAE: 0.2595 - val_loss: 0.3023 - val_RMSE: 0.5418 - val_MAE: 0.4292\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1727 - RMSE: 0.4048 - MAE: 0.2779 - val_loss: 0.3046 - val_RMSE: 0.5439 - val_MAE: 0.4309\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1622 - RMSE: 0.3917 - MAE: 0.2640 - val_loss: 0.3108 - val_RMSE: 0.5497 - val_MAE: 0.4333\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1902 - RMSE: 0.4260 - MAE: 0.2835 - val_loss: 0.3177 - val_RMSE: 0.5559 - val_MAE: 0.4332\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1708 - RMSE: 0.4026 - MAE: 0.2768 - val_loss: 0.3152 - val_RMSE: 0.5537 - val_MAE: 0.4291\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1697 - RMSE: 0.4013 - MAE: 0.2803 - val_loss: 0.3153 - val_RMSE: 0.5537 - val_MAE: 0.4271\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1696 - RMSE: 0.4011 - MAE: 0.2791 - val_loss: 0.3177 - val_RMSE: 0.5558 - val_MAE: 0.4281\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1681 - RMSE: 0.3991 - MAE: 0.2719 - val_loss: 0.3250 - val_RMSE: 0.5622 - val_MAE: 0.4346\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1785 - RMSE: 0.4118 - MAE: 0.2782 - val_loss: 0.3319 - val_RMSE: 0.5683 - val_MAE: 0.4428\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1729 - RMSE: 0.4050 - MAE: 0.2764 - val_loss: 0.3357 - val_RMSE: 0.5717 - val_MAE: 0.4515\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1598 - RMSE: 0.3886 - MAE: 0.2635 - val_loss: 0.3371 - val_RMSE: 0.5730 - val_MAE: 0.4507\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1675 - RMSE: 0.3983 - MAE: 0.2766 - val_loss: 0.3304 - val_RMSE: 0.5669 - val_MAE: 0.4369\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1562 - RMSE: 0.3835 - MAE: 0.2639 - val_loss: 0.3121 - val_RMSE: 0.5503 - val_MAE: 0.4155\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1693 - RMSE: 0.4000 - MAE: 0.2849 - val_loss: 0.3054 - val_RMSE: 0.5440 - val_MAE: 0.4040\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1626 - RMSE: 0.3913 - MAE: 0.2755 - val_loss: 0.3121 - val_RMSE: 0.5502 - val_MAE: 0.4082\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1635 - RMSE: 0.3928 - MAE: 0.2711 - val_loss: 0.3402 - val_RMSE: 0.5755 - val_MAE: 0.4314\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1731 - RMSE: 0.4052 - MAE: 0.2689 - val_loss: 0.3518 - val_RMSE: 0.5858 - val_MAE: 0.4565\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1579 - RMSE: 0.3864 - MAE: 0.2654 - val_loss: 0.3613 - val_RMSE: 0.5940 - val_MAE: 0.4738\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1840 - RMSE: 0.4189 - MAE: 0.2751 - val_loss: 0.3491 - val_RMSE: 0.5836 - val_MAE: 0.4680\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1690 - RMSE: 0.4006 - MAE: 0.2740 - val_loss: 0.3270 - val_RMSE: 0.5644 - val_MAE: 0.4498\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1529 - RMSE: 0.3799 - MAE: 0.2590 - val_loss: 0.2908 - val_RMSE: 0.5311 - val_MAE: 0.4172\n",
      "Epoch 99/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1581 - RMSE: 0.3863 - MAE: 0.2634 - val_loss: 0.2730 - val_RMSE: 0.5139 - val_MAE: 0.3994\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1607 - RMSE: 0.3896 - MAE: 0.2680 - val_loss: 0.2786 - val_RMSE: 0.5194 - val_MAE: 0.3997\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1631 - RMSE: 0.3928 - MAE: 0.2681 - val_loss: 0.2816 - val_RMSE: 0.5225 - val_MAE: 0.4135\n",
      "Epoch 102/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1506 - RMSE: 0.3768 - MAE: 0.2627"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "num_epochs = 1000\n",
    "model = NAM(7)\n",
    "checkpoint_filepath = \"./data/tmp/checkpoint_NAM\"\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"MAE\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "early_stoping_callback = keras.callbacks.EarlyStopping(monitor='loss', patience=100)\n",
    "\n",
    "history = model.fit(\n",
    "        x=np.reshape(X_train,(X_train.shape[0],1,X_train.shape[1])), \n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback,early_stoping_callback],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8aa912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"]=(13,7)\n",
    "plt.plot(history.history[\"RMSE\"])\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"MAE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4048f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_filepath)\n",
    "y_pred = model(np.reshape(X_train,(X_train.shape[0],1,X_train.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db6286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(tf.reshape(y_pred,(-1,1))*std+mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c45f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train*std+mean)\n",
    "plt.plot(tf.reshape(y_pred,(-1,1))*std+mean,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a2f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(np.reshape(y_train,(-1))-np.reshape(y_pred,(-1)))*std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3313cb9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.reshape(y_pred,(-1))-np.reshape(y_train,(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b316431",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(np.reshape(X_test,(X_test.shape[0],1,X_test.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d092f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test*std+mean)\n",
    "plt.plot(y_pred*std+mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c3151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(np.reshape(y_test,(-1))-np.reshape(y_pred,(-1)))*std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e8893",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test-y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840e3f42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
